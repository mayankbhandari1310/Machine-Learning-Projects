{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_recog_data = pd.read_csv('fer2013.csv')\n",
    "face_recog_data.head()\n",
    "\n",
    "train_data = face_recog_data[[\"emotion\", \"pixels\"]][face_recog_data[\"Usage\"] == \"Training\"]\n",
    "test_data = face_recog_data[[\"emotion\", \"pixels\"]][face_recog_data[\"Usage\"] == \"PublicTest\"]\n",
    "\n",
    "#loading training data\n",
    "training_target_values = np.array(train_data['emotion'])\n",
    "training_target_values = training_target_values.astype(np.float32)\n",
    "training_input_face_images = np.vstack((train_data['pixels'].apply(lambda pixel : np.fromstring(pixel, sep=' '))))\n",
    "training_input_face_images = np.reshape(training_input_face_images, (training_input_face_images.shape[0], 48, 48))\n",
    "training_input_face_images = training_input_face_images.astype(np.float32)\n",
    "training_input_face_images = training_input_face_images\n",
    "\n",
    "#loading test data\n",
    "testing_target_values = np.array(test_data['emotion'])\n",
    "testing_target_values = testing_target_values.astype(np.float32)\n",
    "testing_input_face_images = np.vstack((test_data['pixels'].apply(lambda pixel : np.fromstring(pixel, sep=' '))))\n",
    "testing_input_face_images = np.reshape(testing_input_face_images, (testing_input_face_images.shape[0], 48, 48))\n",
    "testing_input_face_images = testing_input_face_images.astype(np.float32)\n",
    "testing_input_face_images = testing_input_face_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48) (28709,)\n",
      "(3589, 48, 48) (3589,)\n"
     ]
    }
   ],
   "source": [
    "print(training_input_face_images.shape, training_target_values.shape)\n",
    "print(testing_input_face_images.shape, testing_target_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_length = 28709\n",
    "#split = int(data_length * 0.8)\n",
    "\n",
    "\n",
    "\n",
    "X_train = training_input_face_images\n",
    "X_val = testing_input_face_images\n",
    "\n",
    "y_train = np_utils.to_categorical(training_target_values[:])\n",
    "y_val = np_utils.to_categorical(training_target_values)\n",
    "\n",
    "#print(X_train.shape, X_val.shape)\n",
    "#print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'[ 1.  0.  0.  0.  0.  0.  0.]')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAE/CAYAAAAnhFRiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14eb5611eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5, 5])\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7) (3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 48, 48, 1)\n",
    "#X_val = X_val.reshape(-1, 48, 48, 1)\n",
    "X_test = testing_input_face_images.reshape(-1, 48,48, 1)\n",
    "y_test = testing_target_values\n",
    "y_test = np_utils.to_categorical(testing_target_values)\n",
    "print(y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "#X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#X_train = X_train/255.0\n",
    "#X_val = X_val/255.0\n",
    "#X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 40\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mayank  Bhandari\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Deep model with less number of layers, lesser max-pools and small dense layers\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    " \n",
    "#fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mayank  Bhandari\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2550: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Mayank  Bhandari\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 19, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 17, 17, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,877,831.0\n",
      "Trainable params: 1,876,999.0\n",
      "Non-trainable params: 832.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 2.4645 - acc: 0.1985Epoch 00000: val_loss improved from inf to 1.82576, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 99s - loss: 2.4642 - acc: 0.1985 - val_loss: 1.8258 - val_acc: 0.2494\n",
      "Epoch 2/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.8819 - acc: 0.2338Epoch 00001: val_loss improved from 1.82576 to 1.80205, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 83s - loss: 1.8820 - acc: 0.2339 - val_loss: 1.8021 - val_acc: 0.2494\n",
      "Epoch 3/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.8255 - acc: 0.2477Epoch 00002: val_loss improved from 1.80205 to 1.79819, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 83s - loss: 1.8253 - acc: 0.2477 - val_loss: 1.7982 - val_acc: 0.2494\n",
      "Epoch 4/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.7889 - acc: 0.2584Epoch 00003: val_loss improved from 1.79819 to 1.74474, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 83s - loss: 1.7889 - acc: 0.2584 - val_loss: 1.7447 - val_acc: 0.2831\n",
      "Epoch 5/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.7434 - acc: 0.2849Epoch 00004: val_loss improved from 1.74474 to 1.68367, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 71s - loss: 1.7432 - acc: 0.2851 - val_loss: 1.6837 - val_acc: 0.2948\n",
      "Epoch 6/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.6933 - acc: 0.3207Epoch 00005: val_loss improved from 1.68367 to 1.64311, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.6933 - acc: 0.3206 - val_loss: 1.6431 - val_acc: 0.3394\n",
      "Epoch 7/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.6430 - acc: 0.3443Epoch 00006: val_loss improved from 1.64311 to 1.56441, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 69s - loss: 1.6432 - acc: 0.3441 - val_loss: 1.5644 - val_acc: 0.3826\n",
      "Epoch 8/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.6065 - acc: 0.3674Epoch 00007: val_loss improved from 1.56441 to 1.50344, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.6063 - acc: 0.3674 - val_loss: 1.5034 - val_acc: 0.4135\n",
      "Epoch 9/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.5726 - acc: 0.3807Epoch 00008: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.5726 - acc: 0.3806 - val_loss: 1.5461 - val_acc: 0.3934\n",
      "Epoch 10/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.5347 - acc: 0.4021Epoch 00009: val_loss improved from 1.50344 to 1.45521, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.5348 - acc: 0.4020 - val_loss: 1.4552 - val_acc: 0.4271\n",
      "Epoch 11/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.5063 - acc: 0.4128Epoch 00010: val_loss improved from 1.45521 to 1.44342, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.5064 - acc: 0.4127 - val_loss: 1.4434 - val_acc: 0.4374\n",
      "Epoch 12/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.4779 - acc: 0.4227Epoch 00011: val_loss improved from 1.44342 to 1.39308, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.4776 - acc: 0.4230 - val_loss: 1.3931 - val_acc: 0.4567\n",
      "Epoch 13/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.4546 - acc: 0.4347Epoch 00012: val_loss improved from 1.39308 to 1.36076, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.4545 - acc: 0.4346 - val_loss: 1.3608 - val_acc: 0.4695\n",
      "Epoch 14/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.4247 - acc: 0.4437Epoch 00013: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.4249 - acc: 0.4437 - val_loss: 1.3714 - val_acc: 0.4678\n",
      "Epoch 15/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.4141 - acc: 0.4522Epoch 00014: val_loss improved from 1.36076 to 1.35222, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.4141 - acc: 0.4522 - val_loss: 1.3522 - val_acc: 0.4661\n",
      "Epoch 16/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3974 - acc: 0.4619Epoch 00015: val_loss improved from 1.35222 to 1.31668, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.3975 - acc: 0.4618 - val_loss: 1.3167 - val_acc: 0.4857\n",
      "Epoch 17/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3747 - acc: 0.4675Epoch 00016: val_loss improved from 1.31668 to 1.28412, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.3747 - acc: 0.4674 - val_loss: 1.2841 - val_acc: 0.4968\n",
      "Epoch 18/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3565 - acc: 0.4761Epoch 00017: val_loss improved from 1.28412 to 1.27665, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.3566 - acc: 0.4760 - val_loss: 1.2767 - val_acc: 0.5010\n",
      "Epoch 19/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3396 - acc: 0.4826Epoch 00018: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.3398 - acc: 0.4826 - val_loss: 1.2839 - val_acc: 0.5068\n",
      "Epoch 20/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3248 - acc: 0.4893Epoch 00019: val_loss improved from 1.27665 to 1.24988, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.3251 - acc: 0.4893 - val_loss: 1.2499 - val_acc: 0.5077\n",
      "Epoch 21/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.3175 - acc: 0.4904Epoch 00020: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.3174 - acc: 0.4905 - val_loss: 1.2613 - val_acc: 0.5052\n",
      "Epoch 22/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2998 - acc: 0.4976Epoch 00021: val_loss improved from 1.24988 to 1.24707, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.2996 - acc: 0.4975 - val_loss: 1.2471 - val_acc: 0.5235\n",
      "Epoch 23/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2932 - acc: 0.5018Epoch 00022: val_loss improved from 1.24707 to 1.23189, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.2933 - acc: 0.5017 - val_loss: 1.2319 - val_acc: 0.5269\n",
      "Epoch 24/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2790 - acc: 0.5130Epoch 00023: val_loss improved from 1.23189 to 1.21215, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.2794 - acc: 0.5129 - val_loss: 1.2121 - val_acc: 0.5283\n",
      "Epoch 25/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2651 - acc: 0.5144Epoch 00024: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.2653 - acc: 0.5143 - val_loss: 1.2260 - val_acc: 0.5222\n",
      "Epoch 26/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2569 - acc: 0.5196Epoch 00025: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.2569 - acc: 0.5195 - val_loss: 1.2238 - val_acc: 0.5350\n",
      "Epoch 27/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2423 - acc: 0.5260Epoch 00026: val_loss improved from 1.21215 to 1.19510, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.2420 - acc: 0.5261 - val_loss: 1.1951 - val_acc: 0.5511\n",
      "Epoch 28/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2232 - acc: 0.5367Epoch 00027: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.2234 - acc: 0.5366 - val_loss: 1.2129 - val_acc: 0.5286\n",
      "Epoch 29/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2214 - acc: 0.5364Epoch 00028: val_loss improved from 1.19510 to 1.16092, saving model to face_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 68s - loss: 1.2217 - acc: 0.5365 - val_loss: 1.1609 - val_acc: 0.5614\n",
      "Epoch 30/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.2118 - acc: 0.5411Epoch 00029: val_loss improved from 1.16092 to 1.15336, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 68s - loss: 1.2119 - acc: 0.5411 - val_loss: 1.1534 - val_acc: 0.5701\n",
      "Epoch 31/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1927 - acc: 0.5477Epoch 00030: val_loss did not improve\n",
      "28709/28709 [==============================] - 68s - loss: 1.1929 - acc: 0.5476 - val_loss: 1.1765 - val_acc: 0.5508\n",
      "Epoch 32/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1919 - acc: 0.5455Epoch 00031: val_loss did not improve\n",
      "28709/28709 [==============================] - 74s - loss: 1.1920 - acc: 0.5455 - val_loss: 1.1631 - val_acc: 0.5600\n",
      "Epoch 33/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1860 - acc: 0.5522Epoch 00032: val_loss did not improve\n",
      "28709/28709 [==============================] - 83s - loss: 1.1857 - acc: 0.5523 - val_loss: 1.1792 - val_acc: 0.5542\n",
      "Epoch 34/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1672 - acc: 0.5584Epoch 00033: val_loss did not improve\n",
      "28709/28709 [==============================] - 83s - loss: 1.1670 - acc: 0.5585 - val_loss: 1.1644 - val_acc: 0.5584\n",
      "Epoch 35/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1558 - acc: 0.5610Epoch 00034: val_loss improved from 1.15336 to 1.14065, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 83s - loss: 1.1553 - acc: 0.5614 - val_loss: 1.1407 - val_acc: 0.5706\n",
      "Epoch 36/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1514 - acc: 0.5632Epoch 00035: val_loss improved from 1.14065 to 1.11200, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 84s - loss: 1.1513 - acc: 0.5633 - val_loss: 1.1120 - val_acc: 0.5787\n",
      "Epoch 37/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1442 - acc: 0.5668Epoch 00036: val_loss did not improve\n",
      "28709/28709 [==============================] - 83s - loss: 1.1441 - acc: 0.5666 - val_loss: 1.1465 - val_acc: 0.5717\n",
      "Epoch 38/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1381 - acc: 0.5720Epoch 00037: val_loss did not improve\n",
      "28709/28709 [==============================] - 83s - loss: 1.1383 - acc: 0.5721 - val_loss: 1.1306 - val_acc: 0.5704\n",
      "Epoch 39/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1207 - acc: 0.5766Epoch 00038: val_loss improved from 1.11200 to 1.10967, saving model to face_model.h5\n",
      "28709/28709 [==============================] - 84s - loss: 1.1209 - acc: 0.5766 - val_loss: 1.1097 - val_acc: 0.5887\n",
      "Epoch 40/40\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.1189 - acc: 0.5777Epoch 00039: val_loss did not improve\n",
      "28709/28709 [==============================] - 83s - loss: 1.1185 - acc: 0.5779 - val_loss: 1.1103 - val_acc: 0.5843\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='face_model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "train_model = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"face_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.974687343087\n",
      "Train accuracy: 63.1996934763\n",
      "Test loss: 1.11034730039\n",
      "Test accuracy: 58.4285316248\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14efa448828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD3CAYAAADormr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14efa2349e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "ypredtemp = np.array([np.argmax(ypred[i]) for i in range(ypred.shape[0])])\n",
    "ytemp = np.array([np.argmax(y_test[i]) for i in range(ypred.shape[0])])\n",
    "\n",
    "cnf_matrix = confusion_matrix(ytemp, ypredtemp)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(cnf_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
